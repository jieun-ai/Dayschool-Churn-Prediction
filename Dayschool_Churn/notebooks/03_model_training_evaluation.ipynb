{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "train_subscriptions = pd.read_csv('../data/processed/train_subscriptions.csv')\n",
    "test_subscriptions = pd.read_csv('../data/processed/test_subscriptions.csv')\n",
    "\n",
    "# 날짜 피처 추출 함수 정의\n",
    "def extract_date_features(df, col):\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')  # 문자열 → datetime 변환\n",
    "    df[f'{col}_month'] = df[col].dt.month\n",
    "    df[f'{col}_day'] = df[col].dt.day\n",
    "    df[f'{col}_hour'] = df[col].dt.hour\n",
    "    df[f'{col}_weekday'] = df[col].dt.dayofweek  # 0 = Monday, 6 = Sunday\n",
    "    return df\n",
    "\n",
    "# 피처 엔지니어링 및 모델 학습·평가\n",
    "date_columns = ['구독_시작일', '구독_종료일']\n",
    "\n",
    "# 날짜 피처 생성 (Train/Test)\n",
    "for col in date_columns:\n",
    "    train_subscriptions = extract_date_features(train_subscriptions, col)\n",
    "    test_subscriptions  = extract_date_features(test_subscriptions, col)\n",
    "\n",
    "# 해지 신청일 NaN 처리\n",
    "def fill_cancel_date(df):\n",
    "    df['해지_신청일'] = df['해지_신청일'].fillna('2000-12-31 00:00:00')\n",
    "    return df\n",
    "\n",
    "train_subscriptions = fill_cancel_date(train_subscriptions)\n",
    "test_subscriptions  = fill_cancel_date(test_subscriptions)\n",
    "\n",
    "# 구독 시작일부터 해지일까지 기간 계산 (일)\n",
    "for df in [train_subscriptions, test_subscriptions]:\n",
    "    df['해지일_diff'] = (pd.to_datetime(df['해지_신청일']) - pd.to_datetime(df['구독_시작일'])).dt.days\n",
    "    df.loc[df['해지_신청일'] == pd.Timestamp('2000-12-31'), '해지일_diff'] = 0\n",
    "\n",
    "# 종속변수(y) 생성\n",
    "y_train = train_subscriptions['구독_상태'].map({'연장': 0, '해지': 1})\n",
    "y_test  = test_subscriptions['구독_상태'].map({'연장': 0, '해지': 1})\n",
    "\n",
    "# 독립변수(X) 설정 (불필요 칼럼 제거)\n",
    "drop_cols = [\n",
    "    '구독_상태', '구독_종료일', '해지까지_일수', '총_구독_일수',\n",
    "    '구독_시작일', '해지_신청일', '구독_종료일_hour',\n",
    "    '구독_종료일_day', '구독_종료일_month',\n",
    "    '총_구독_횟수', 'track_participation', 'progress_zscore_by_project'\n",
    "]\n",
    "X_train = train_subscriptions.drop(columns=drop_cols)\n",
    "X_test  = test_subscriptions.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/song/opt/anaconda3/envs/song38/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1614, number of negative: 1163\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1797\n",
      "[LightGBM] [Info] Number of data points in the train set: 2777, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.581203 -> initscore=0.327713\n",
      "[LightGBM] [Info] Start training from score 0.327713\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  accuracy  f1_score\n",
       "1  LogisticRegression  0.956522  0.952381\n",
       "0        RandomForest  0.913043  0.909091\n",
       "2    GradientBoosting  0.869565  0.869565\n",
       "3             XGBoost  0.826087  0.833333\n",
       "4            LightGBM  0.826087  0.833333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ 최고 f1_score 모델: LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=11),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=11),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=11),\n",
    "    'LightGBM': LGBMClassifier(random_state=11)\n",
    "}\n",
    "\n",
    "# 실험 결과 저장용 리스트\n",
    "experiment_results = []\n",
    "\n",
    "# 모델 학습 및 평가 루프\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    experiment_results.append({\n",
    "        'model': name,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'f1_score': f1_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "# 결과 DataFrame 변환 및 분석\n",
    "experiment_df = pd.DataFrame(experiment_results)\n",
    "display(experiment_df.sort_values('f1_score', ascending=False))\n",
    "\n",
    "# 최고 f1_score 모델 출력\n",
    "best_model_name = experiment_df.loc[experiment_df['f1_score'].idxmax(), 'model']\n",
    "print(f\"▶️ 최고 f1_score 모델: {best_model_name}\")\n",
    "best_model = models[best_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/song/opt/anaconda3/envs/song38/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1614, number of negative: 1163\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1797\n",
      "[LightGBM] [Info] Number of data points in the train set: 2777, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.581203 -> initscore=0.327713\n",
      "[LightGBM] [Info] Start training from score 0.327713\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  accuracy  recall  precision  f1_score\n",
       "1  LogisticRegression  0.956522     1.0   0.909091  0.952381\n",
       "0        RandomForest  0.913043     1.0   0.833333  0.909091\n",
       "2    GradientBoosting  0.869565     1.0   0.769231  0.869565\n",
       "3             XGBoost  0.826087     1.0   0.714286  0.833333\n",
       "4            LightGBM  0.826087     1.0   0.714286  0.833333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ 최고 f1_score 모델: LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score  # precision_score 추가\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=11),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=11),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=11),\n",
    "    'LightGBM': LGBMClassifier(random_state=11)\n",
    "}\n",
    "\n",
    "# 실험 결과 저장용 리스트\n",
    "experiment_results = []\n",
    "\n",
    "# 모델 학습 및 평가 루프\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    experiment_results.append({\n",
    "        'model': name,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),  # 이전에 추가된 Recall\n",
    "        'precision': precision_score(y_test, y_pred),  # Precision 추가\n",
    "        'f1_score': f1_score(y_test, y_pred)\n",
    "    }) \n",
    "\n",
    "# 결과 DataFrame 변환 및 분석\n",
    "experiment_df = pd.DataFrame(experiment_results)\n",
    "display(experiment_df.sort_values('f1_score', ascending=False))\n",
    "\n",
    "# 최고 f1_score 모델 출력\n",
    "best_model_name = experiment_df.loc[experiment_df['f1_score'].idxmax(), 'model']\n",
    "print(f\"▶️ 최고 f1_score 모델: {best_model_name}\")\n",
    "best_model = models[best_model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 구독 해지 예측 사용자 메일링 리스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# from pathlib import Path\n",
    "\n",
    "# # 1) 모델 예측 (확률, 예측값)\n",
    "# y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "# y_pred = best_model.predict(X_test)\n",
    "\n",
    "# # 2) 운영용 DataFrame 생성: user_id ➡ test_meta에서 가져온 구독_시작일 ➡ 이메일\n",
    "# oper_df = X_test[['user_id']].copy()\n",
    "\n",
    "# # 2-1) test_meta와 병합해서 원본 구독_시작일(datetime) 붙이기\n",
    "# test_subscriptions = pd.read_csv('../data/processed/test_subscriptions.csv', parse_dates=['구독_시작일'])\n",
    "# test_meta = test_subscriptions[['user_id', '구독_시작일']].copy()\n",
    "# oper_df = oper_df.merge(test_meta[['user_id', '구독_시작일']], on  ='user_id', how ='left')\n",
    "\n",
    "# # 2-2) 이메일 정보 병합\n",
    "# user_mail = pd.read_csv('../data/processed/user.csv')\n",
    "# oper_df = oper_df.merge(user_mail[['user_id', 'mail']], on  ='user_id', how ='left')\n",
    "\n",
    "# # 3) 모델 예측 결과를 컬럼으로 추가\n",
    "# oper_df['해지할 확률'] = y_pred_proba\n",
    "# oper_df['구독_상태 예측'] = np.where(y_pred == 1, '해지', '연장')\n",
    "\n",
    "# # 4) 운영용 필터링: “해지”로 예측된 유저만 추출\n",
    "# mail_list = oper_df[oper_df['구독_상태 예측'] == '해지'][['user_id', 'mail', '구독_시작일', '해지할 확률']].copy()\n",
    "\n",
    "# # 5) 컬럼명 한글화 (원하시는 대로 바꿔주세요)\n",
    "# mail_list = mail_list.rename(columns={\n",
    "#     'user_id'    : '사용자_ID',\n",
    "#     'email'      : '이메일',\n",
    "#     '구독_시작일' : '구독_시작일',\n",
    "#     '해지할 확률' : '해지할 확률'\n",
    "# })\n",
    "\n",
    "# mail_list = mail_list.sort_values(by = '구독_시작일')\n",
    "# display(mail_list)\n",
    "\n",
    "# # 6) CSV 저장 (운영용)\n",
    "# today_str = pd.to_datetime('2025-02-26').strftime('%Y-%m-%d')  # pd.to_datetime('today').normalize()\n",
    "\n",
    "# base = Path(\"../data/results\")\n",
    "# mail_dir = base / \"mail\"\n",
    "# mail_list.to_csv(mail_dir / f\"{today_str}_mail_list.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 구독 해지 예측 디버깅 테이블 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug_df = X_test[['user_id']].copy()\n",
    "# debug_df = debug_df.merge(test_meta[['user_id', '구독_시작일']], on  ='user_id', how ='left')\n",
    "# debug_df = debug_df.merge(user_mail[['user_id', 'mail']], on  ='user_id', how ='left')\n",
    "\n",
    "# debug_df['해지할 확률'] = y_pred_proba\n",
    "# debug_df['구독 상태 예측'] = np.where(y_pred == 1, '해지', '연장')\n",
    "# debug_df['구독 상태 실제 결과'] = np.where(y_test.values == 1, '해지', '연장')\n",
    "\n",
    "# debug_df = debug_df.rename(columns={\n",
    "#     'user_id'             : '사용자_ID',\n",
    "#     'mail'               : '이메일',\n",
    "#     '구독_시작일'          : '구독_시작일',\n",
    "#     '해지할 확률'          : '해지할 확률',\n",
    "#     '구독 상태 예측'       : '구독 상태 예측',\n",
    "#     '구독 상태 실제 결과'  : '구독 상태 실제 결과'\n",
    "# })\n",
    "# debug_df = debug_df.sort_values(by = '구독_시작일')\n",
    "# display(debug_df)\n",
    "\n",
    "# debug_dir = base / \"debug\"\n",
    "# # f1_score 기준 내림차순 정렬\n",
    "# score = experiment_df.sort_values('f1_score', ascending=False)\n",
    "\n",
    "# # 최고 점수, 모델명 추출\n",
    "# best_model_name = score.iloc[0]['model']\n",
    "# best_f1_score = score.iloc[0]['f1_score']\n",
    "\n",
    "# # 파일명 만들기\n",
    "# filename = f\"{today_str}_prediction_debug_{best_model_name}_{best_f1_score:.4f}.csv\"\n",
    "\n",
    "# # 저장\n",
    "# debug_df.to_csv(debug_dir / filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "song38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
